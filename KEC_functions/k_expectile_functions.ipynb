{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.preprocessing import StandardScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Euclidian distance\n",
    "def dist(a, b):\n",
    "    return np.linalg.norm(a - b, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tau distance between point a and centroid m\n",
    "# tau variate among different dimensions and different groups\n",
    "def dist_fun_vtau(a,m,tau):\n",
    "    dist = np.zeros(len(m))\n",
    "    for i in range(len(m)):\n",
    "        d = a - m[i]\n",
    "        ele = 0\n",
    "        for j in range(len(d)):\n",
    "            col = d[j]\n",
    "            ad = (1-tau[i,j])* sum(col[col<0]**2) + tau[i,j]* sum(col[col>=0]**2)\n",
    "            ele = ele + ad\n",
    "        dist[i] = ele\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tau distance between point a and centroid m\n",
    "# uniform tau among groups, tau can be the same or different among dimensions\n",
    "def dist_fun_utau(a,m,tau):\n",
    "    dist = np.zeros(len(m))\n",
    "    for i in range(len(m)):\n",
    "        d = a - m[i]\n",
    "        ele = 0\n",
    "        for j in range(len(tau)):\n",
    "            col = d[j]\n",
    "            ad = (1-tau[j])* sum(col[col<0]**2) + tau[j]* sum(col[col>=0]**2)\n",
    "            ele = ele + ad\n",
    "        dist[i] = ele\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate expectile of a group\n",
    "def expectile_fun(group, tau):\n",
    "    e = np.mean(group, axis=0)\n",
    "    e_new = np.zeros(e.shape)\n",
    "    while dist(e_new , e) != 0:\n",
    "        c = group[:,:]- e\n",
    "        e = copy.deepcopy(e_new)\n",
    "        for i in range(len(c[0])):\n",
    "            d = c[:,i]\n",
    "            a_co = group[:,i]\n",
    "            neg = a_co[d<0]\n",
    "            pos = a_co[d>=0]\n",
    "            norm = tau[i]*len(pos)+ (1-tau[i])*len(neg)\n",
    "            e_new[i] = (tau[i]* sum(pos) + (1-tau[i])* sum(neg))/norm\n",
    "    return  e_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tau\n",
    "def tau_fun(points, mu):\n",
    "    tau_list = []\n",
    "    dis = points - mu\n",
    "    for i in range(len(mu)):\n",
    "        res = dis[:,i]\n",
    "        e_neg = -sum(res[res < 0])/len(res[res < 0])\n",
    "        e_pos = sum(res[res >= 0])/len(res[res >= 0])\n",
    "        c = e_neg/e_pos\n",
    "        tau = c/(1+c)\n",
    "        tau_list.append(tau)\n",
    "    return tau_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tau_fun(group, e):\n",
    "    res = group - e\n",
    "    neg = np.array([res<0],dtype = np.int32)\n",
    "    pos = np.array([res>=0],dtype= np.int32)\n",
    "    neg_s = -(neg*res).sum(axis=1)/neg.sum(axis=1)\n",
    "    pos_s = (pos*res).sum(axis=1)/pos.sum(axis=1)\n",
    "    c = neg_s/pos_s\n",
    "    tau = c/(1+c)\n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K expectile clustering with pre-specified tau vector\n",
    "def k_expectile_utau(X, k, tau): \n",
    "    X = np.array(X)\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    C = kmeans.cluster_centers_\n",
    "\n",
    "# To store the value of centroids when it updates\n",
    "    C_old = np.zeros(C.shape)\n",
    "# Cluster Lables(0, 1, 2)\n",
    "    clusters = np.zeros(len(X))\n",
    "# Error func. - Distance between new centroids and old centroids\n",
    "    error = dist(C, C_old)\n",
    "# Loop will run till the error becomes zero\n",
    "    while error != 0:\n",
    "    # Assigning each value to its closest cluster\n",
    "        for i in range(len(X)):\n",
    "            distances = dist_fun_utau(X[i], C, tau)\n",
    "            cluster = np.argmin(distances)\n",
    "            clusters[i] = cluster\n",
    "    # Storing the old centroid values\n",
    "        C_old = copy.deepcopy(C)\n",
    "    # Finding the new centroids by taking the average value\n",
    "        for d in range(k):\n",
    "            points = [X[i] for i in range(len(X)) if clusters[i] == d]\n",
    "            points = np.array(points)\n",
    "            C[d] = expectile_fun(points,tau)\n",
    "        error = dist(C, C_old)\n",
    "    return C, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K expectile clustering with unknown taus\n",
    "def k_expectile_vtau(X, k): \n",
    "    X = np.array(X)\n",
    "# Initialize cluster centers as K means cluster centers\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    C = kmeans.cluster_centers_\n",
    "\n",
    "# To store the value of centroids when it updates\n",
    "    C_old = np.zeros(C.shape)\n",
    "    clusters = np.zeros(len(X))\n",
    "# Initialize tau = 0.5\n",
    "    tau_list = np.ones((k, len(C[0])))*0.5\n",
    "# Error func. - Distance between new centroids and old centroids\n",
    "    error = dist(C, C_old)\n",
    "# Loop will run till the error \n",
    "    while error >= 0.05:\n",
    "    # Assigning each value to its closest cluster\n",
    "        for i in range(len(X)):\n",
    "            for j in range (len(C[0])):\n",
    "                distances = dist_fun_vtau(X[i], C, tau_list)\n",
    "                cluster = np.argmin(distances)\n",
    "                clusters[i] = cluster\n",
    "    # Storing the old centroid values\n",
    "        C_old = copy.deepcopy(C)\n",
    "    # Finding the new centroids and tau\n",
    "        for d in range(k):\n",
    "            points = [X[i] for i in range(len(X)) if clusters[i] == d]\n",
    "            points = np.array(points)\n",
    "    # Updating taus\n",
    "            tau = tau_fun(points,C[d])\n",
    "            C[d] = expectile_fun(points,tau)\n",
    "            tau_list[d] = tau\n",
    "        error = dist(C, C_old)\n",
    "        print(tau_list)\n",
    "        print(error)\n",
    "    return C, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean distance\n",
    "def dist(a, b):\n",
    "    return np.linalg.norm(a - b, None)\n",
    "#Tau-distance\n",
    "def tau_dist_fun(x, centroid, tau):\n",
    "    arr = x - centroid\n",
    "    tau_ar = tau[None:,:]\n",
    "    neg = np.array([arr<0],dtype=np.int32)\n",
    "    pos = np.array([arr>=0],dtype=np.int32)\n",
    "    w_pos = pos * tau_ar\n",
    "    w_neg = neg * (1-tau_ar)\n",
    "    dist = (arr ** 2 * w_pos).sum(axis = arr.ndim) + (arr ** 2 * w_neg).sum(axis = arr.ndim)\n",
    "    return dist\n",
    "#get centroids\n",
    "def get_closest_centroid(x, centroid, tau):\n",
    "    # Loop over each centroid and compute the distance from data point.\n",
    "    dist = tau_dist_fun(x, centroid, tau)\n",
    "    # Get the index of the centroid with the smallest distance to the data point\n",
    "    assigned_centroids = np.argmin(dist, axis = 2)\n",
    "    clusters = np.squeeze(assigned_centroids)\n",
    "    return clusters\n",
    "#Expectile estimation\n",
    "def expectile_fun_c(group, tau):\n",
    "    e = np.mean(group, axis=0)\n",
    "    e_new = np.zeros(e.shape)\n",
    "    while dist(e_new , e) != 0:\n",
    "        res = group - e\n",
    "        e = copy.deepcopy(e_new)\n",
    "        neg = np.array([res<0],dtype = np.int32)\n",
    "        pos = np.array([res>=0],dtype= np.int32)\n",
    "        norm = pos.sum(axis=1)*tau + neg.sum(axis=1)*(1-tau)\n",
    "        e_arr = (tau * (group * pos).sum(axis=1) + (1-tau) * (group * neg).sum(axis=1))/norm\n",
    "        e_new = np.squeeze(e_arr)\n",
    "    return e_new\n",
    "#Estimate optimal taus\n",
    "def tau_fun_c(group, e):\n",
    "    res = group - e\n",
    "    neg = np.array([res<0],dtype = np.int32)\n",
    "    pos = np.array([res>=0],dtype= np.int32)\n",
    "    neg_s = -(neg*res).sum(axis=1)/neg.sum(axis=1)\n",
    "    pos_s = (pos*res).sum(axis=1)/pos.sum(axis=1)\n",
    "    c = neg_s/pos_s\n",
    "    tau = c/(1+c)\n",
    "    return tau\n",
    "# Define K expectile clustering \n",
    "# Main function\n",
    "def k_expectile_vtau_c(X, k):\n",
    "    X = np.array(X)\n",
    "# Initialize cluster centers as K means cluster centers\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    C = kmeans.cluster_centers_\n",
    "\n",
    "# To store the value of centroids when it updates\n",
    "    C_old = np.zeros(C.shape)\n",
    "# Initialize tau = 0.5\n",
    "    tau = np.ones(C.shape)*0.5\n",
    "# Error func. - Distance between new centroids and old centroids\n",
    "    error = dist(C, C_old)\n",
    "# main loop   \n",
    "    for r in range(30):\n",
    "        # Get closest centroids to each data point\n",
    "        assigned_clusters = get_closest_centroid(X[:, None, :], C[None,:, :], tau)\n",
    "        # Storing the old centroid values\n",
    "        C_old = copy.deepcopy(C)\n",
    "        # Compute new centroids\n",
    "        for c in range(k):\n",
    "            # Get data points belonging to each cluster \n",
    "            cluster_members = X[assigned_clusters == c]\n",
    "        \n",
    "            # Compute the centroids of the clusters\n",
    "            C[c] = expectile_fun_c(cluster_members, tau[c])\n",
    "        \n",
    "            # Update the tau\n",
    "            tau[c] = tau_fun_c(cluster_members, C[c])\n",
    "        error = dist(C, C_old)\n",
    "        print(tau)\n",
    "        print(error)\n",
    "    return C, assigned_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "num_iters = 50\n",
    "num_clusters = 4\n",
    "\n",
    "\n",
    "# sample from Gaussians \n",
    "data1 = np.random.normal((5,5,5), (4, 4, 4), (data_size,3))\n",
    "data2 = np.random.normal((4,20,20), (3,3,3), (data_size, 3))\n",
    "data3 = np.random.normal((25, 20, 5), (5, 5, 5), (data_size,3))\n",
    "data4 = np.random.normal((30, 30, 30), (5, 5, 5), (data_size,3))\n",
    "\n",
    "# Combine the data to create the final dataset\n",
    "data = np.concatenate((data1,data2, data3, data4), axis = 0)\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Set random seed for reproducibility \n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49748238 0.49748238 0.50654582]\n",
      " [0.49598394 0.50803213 0.51104418]\n",
      " [0.475      0.518      0.515     ]\n",
      " [0.48664688 0.49950544 0.50346192]]\n",
      "3.9859325923993215e-14\n"
     ]
    }
   ],
   "source": [
    "C_e, clusters_e = k_expectile_vtau_c(data, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
